{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a model for exploratory analysis based on a tutorial from Giraffa, Iona Barbos.\n",
    "The methodology is complete and logical in progression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is based upon casino customer gaming manetary transactions. There are two levels of transactions, each\n",
    "with a deposit and a withdrawal. L1 transactions are customer deposits to/withdrawal from their gambling account.L2 transactions are deposits to/withdrawals from the customer gaming account for gambling activities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.mode.chained_assignment = None\n",
    "from datetime import datetime as dt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tidy up data appearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:20.2f}'.format\n",
    "pd.set_option('display.max_columns', 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Online_casino_DIB.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the shape, datatype and info for the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(exclude='float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReqTimeUTC is type obj so convert it to date time\n",
    "ReqTimeUTC has a number of digits in the entry for the time. If we are not going to use time you can clean up the entry by stripping of the time component of the entry - see the code line in the markdown\n",
    "ReqTimeUTC has date/time entries beyond 2020-02-29 so exclude those values\n",
    "Data is being excluded so create new df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = df[df.ReqTimeUTC <= '2020-02-29 00:00:00+00:00']\\\n",
    "    .copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['ReqTimeUTC'] = pd.to_datetime(df_raw['ReqTimeUTC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't want the time elements for future use you can remove them using the following code line\n",
    "\n",
    "df_raw['ReqTimeUTC'] = df_raw['ReqTimeUTC'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the Transaction type column\n",
    " Transactions labeled as “LOYALTYCARDDEBIT” are Level 2 deposits. \n",
    " Transactions labeled as “LOYALTYCARDCREDIT” are Level 2 withdrawals. \n",
    " Transactions labeled as “LOYALTYCARDCREDITCL” or “LOYALTYCARDCREDITACH” are Level 1 deposits \n",
    " made via a card or ACH respectively.\n",
    "\n",
    "Map\n",
    " LOYALTYCARDDEBIT = L2D\n",
    " LOYALTYCARDCREDIT = L2W\n",
    " LOYALTYCARDCREDITCL = L1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.describe(exclude='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['TransactionType'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map the shortforms into the df column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.TransactionType = df_raw.TransactionType\\\n",
    "    .map({'LOYALTYCARDDEBIT':'L2D','LOYALTYCARDCREDITCL':'L1D',\n",
    "          'LOYALTYCARDCREDIT':'L2W'})\n",
    "\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplify the AccountIdentifier column by stripping off 'Customer' with regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['AccountIdentifier'] = df_raw['AccountIdentifier']\\\n",
    "    .str.replace(r'^customer','',\n",
    "                                                                      regex=True)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename some of the columns to more useable form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.rename(columns= {'AccountIdentifier':'user', 'ReqTimeUTC':'date',\n",
    "                        'TransactionAmount':'amount', \n",
    "                        'TransactionType':'type',\n",
    "                        'Status':'status'},inplace=True)\n",
    "\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group data by users by user and type \n",
    "Create df for user type and define - user_type_\n",
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.groupby(['user', 'type']).count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_type_ = df_raw.groupby(['user', 'type']).count()\\\n",
    "    .reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=user_type_, x='date', bins=50, \n",
    "             hue='type',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histplot even with hue is not very informative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=user_type_, x='date', hue='type',\n",
    "             cumulative=True, stat='density', \n",
    "             element='step', fill=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cumulative version of the histplot is more informative.\n",
    "L2D activities closely follows LD1 activities\n",
    "There is more separation between the L#D activities and the L2W activities\n",
    "\n",
    "In further analysis we will drop the L1D activities and keep on the L2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_working = df_raw.copy()\n",
    "df_working.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_working.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_working = df_working[(df_working.type == \"L2D\") & \\\n",
    "    (df_working.status == \"APPROVED\")].reset_index(drop=True)\n",
    "\n",
    "df_working.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_working = df_working[['user', 'date', 'type', 'amount']]\n",
    "\n",
    "df_working = df_working.sort_values(['user', 'date'])\\\n",
    "    .reset_index(drop=True)\n",
    "\n",
    "df_working.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to see if the patrons who make the most frequent deposits also the patrons who deposit the most money.\n",
    "Look at the data for the top 20 depositors\n",
    "1. Get a frequency count\n",
    "2. Reset the index\n",
    "3. Select the first 2 columns\n",
    "4. Sort by date, reversee the sort and take the top 20 values\n",
    "5. Put the top 20 in a new df and clean it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_working.groupby('user').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_working.groupby('user').count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_working.groupby('user').count().reset_index() \\\n",
    "    .iloc[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_working.groupby('user').count().reset_index() \\\n",
    "    .iloc[:,0:2].sort_values(\"date\")[::-1][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top20_freq = df_working.groupby('user').count()\\\n",
    "    .reset_index()\\\n",
    "    .iloc[:,0:2].sort_values(\"date\")[::-1][0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a similar activity for the top spenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top20_spenders = df_working[['user', 'amount' ]] \\\n",
    "    .groupby('user').sum().reset_index()\\\n",
    "        .sort_values('amount') \\\n",
    "        [::-1][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top20_spenders.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Top 20 side-by-side (ncols=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "\n",
    "sns.barplot(df_top20_freq, x='date', y='user', \n",
    "            ax = ax[0])\n",
    "sns.barplot(df_top20_spenders, x='amount', \n",
    "            y='user', ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows that the most frequent patrons are not the same as the patrons who deposit the most money\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work the date column to see what can extracted from it\n",
    "Extract the hour from the date column\n",
    "Extract the day of the week from the date column\n",
    "Create new columns in the df for each of these elements\n",
    "The day of the week is initiall presented as integers 0-6 Mon-Sun\n",
    "Create dictionary to convert day of the week from int to day name and map to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_working.date.dt.hour\n",
    "df_working['hour'] = df_working.date.dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_working.date.dt.day_of_week\n",
    "df_working['day_of_week'] = df_working.date.dt\\\n",
    "    .day_of_week\n",
    "df_working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_of_the_week_dict = {0: 'Monday',\n",
    "                        1: 'Tuesday',\n",
    "                        2: 'Wednesday',\n",
    "                        3: 'Thursday',\n",
    "                        4: 'Friday',\n",
    "                        5: 'Saturday',\n",
    "                        6: 'Sunday',\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_working['day_of_week'] = df_working['day_of_week']\\\n",
    "    .map(day_of_the_week_dict)\n",
    "df_working"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the day and time of day data are there any patterns that are evident by plotting these data.\n",
    "Create a heat map for this\n",
    "Creating a heat map requires some manipulation of the data into a 'confusion matrix' where the day of the week is the index with the hours of the day as the columns of the matrix\n",
    "Use the pivot table method from pandas to create the confusion matrix from the df we created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_working[['hour', 'day_of_week', 'type']]\\\n",
    "    .groupby(['hour', 'day_of_week']).count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_d_g = df_working[['hour', 'day_of_week', 'type']]\\\n",
    "    .groupby(['hour', 'day_of_week']).count().reset_index()\n",
    "    \n",
    "h_d_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heatmap = pd.pivot_table(h_d_g, values='type', index='day_of_week',\n",
    "                            columns='hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine daily activity\n",
    "How patrons made deposits in a day \n",
    "and what were the values\n",
    "Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_working.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_activity = df_working.groupby(['user', 'date']) \\\n",
    "    .agg({'amount': 'sum', 'type': 'count'}) \\\n",
    "        .reset_index()\n",
    "        \n",
    "daily_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_activity[daily_activity.user==\"customer1\"][0:20]\n",
    "\n",
    "daily_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = daily_activity[daily_activity.user == '1'][0:20]\n",
    "c1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looking at customer 1 there are gaps in the time line \n",
    "where this customer was not active\n",
    "This gap will not let us plot the data\n",
    "Create new df for customer 1 and fill in the gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_1_df = daily_activity[daily_activity.user == '1']\n",
    "user_1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_customer_df = pd.DataFrame()\n",
    "\n",
    "for customer_id in daily_activity.user.unique():\n",
    "    customer_df = daily_activity[daily_activity\\\n",
    "        .user == customer_id]\n",
    "    \n",
    "    full_range = pd.date_range(customer_df.date.min(),\n",
    "                           customer_df.date.max(), freq='D')\n",
    "    \n",
    "    customer_df = customer_df.set_index(keys = 'date')\n",
    "    \n",
    "    customer_df = customer_df.reindex(list(full_range), \n",
    "                                      fill_value=0)\n",
    "    customer_df.user = [customer_id]*len(customer_df)\n",
    "    \n",
    "    customer_df = customer_df.reset_index()\n",
    "    full_customer_df = pd.concat([full_customer_df, customer_df])\n",
    "    \n",
    "full_customer_df = full_customer_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_customer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work up a Sankey plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_customer_df['month'] = full_customer_df.date.dt.\\\n",
    "    to_period('M')\n",
    "\n",
    "customer_month = full_customer_df.groupby(['month', 'user']) \\\n",
    "    .count().reset_index().iloc[:, :2]\n",
    "    \n",
    "start_ = customer_month.groupby('user').min().reset_index()\n",
    "\n",
    "end_ = customer_month.groupby('user').max().reset_index()\n",
    "\n",
    "start_end_df = pd.merge(start_, end_, on='user')\n",
    "\n",
    "start_end_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_target_value = start_end_df.groupby(['month_x', 'month_y']) \\\n",
    "    .count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_target_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use LabelEncoder to get data into shape for Sankey plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit_transform(source_target_value.month_x.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Sankey(node=dict(\n",
    "    pad=100,\n",
    "    thickness = 10,\n",
    "    line = dict(color = 'gray', width = 0.5),\n",
    "    label = ['Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug',\n",
    "            'Sep', 'Oct', 'Nov', 'Dec', 'Jan', 'Feb' ],\n",
    "    color = 'orange'),\n",
    "                  link = dict(\n",
    "                      source = le.transform(source_target_value.month_x.tolist()),\n",
    "                      target = le.transform(source_target_value.month_y.tolist()),\n",
    "                      value = source_target_value.user.tolist(),\n",
    "                      hovercolor=['black']\n",
    "))])\n",
    "\n",
    "fig.update_layout(title_text=\"Customer Lifetime: Mar - Feb\",\n",
    "                  font_size=10)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
